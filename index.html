<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>VR Classroom Exposure Therapy</title>
  <script src="https://aframe.io/releases/1.4.2/aframe.min.js"></script>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      overflow: hidden;
      background: linear-gradient(135deg, #E8F4F8 0%, #F0F8FA 100%);
    }

    #vrOverlay {
      position: fixed;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      backdrop-filter: blur(8px);
      background: rgba(232, 244, 248, 0.85);
      display: flex;
      align-items: center;
      justify-content: center;
      z-index: 1000;
      transition: opacity 0.5s ease;
    }

    #vrOverlay.hidden {
      opacity: 0;
      visibility: hidden;
      pointer-events: none;
    }

    .overlay-card {
      max-width: 420px;
      width: 90%;
      background: white;
      border-radius: 16px;
      padding: 24px;
      box-shadow: 0 10px 40px rgba(19, 52, 59, 0.15);
    }

    .overlay-card h1 {
      font-size: 20px;
      color: rgba(19, 52, 59, 1);
      margin-bottom: 8px;
      font-weight: 600;
    }

    .overlay-card p {
      font-size: 13px;
      color: rgba(19, 52, 59, 0.7);
      margin-bottom: 20px;
      line-height: 1.5;
    }

    #conversationDisplay {
      max-height: 200px;
      overflow-y: auto;
      margin-bottom: 16px;
      padding: 12px;
      background: rgba(232, 244, 248, 0.5);
      border-radius: 8px;
    }

    .message {
      margin-bottom: 10px;
      padding: 8px;
      border-radius: 6px;
      font-size: 12px;
      line-height: 1.4;
    }

    .message.system {
      background: rgba(33, 128, 141, 0.1);
      border-left: 3px solid rgba(33, 128, 141, 1);
    }

    .message.user {
      background: rgba(94, 82, 64, 0.1);
      border-left: 3px solid rgba(94, 82, 64, 0.8);
    }

    .message strong {
      font-weight: 600;
      margin-right: 4px;
    }

    #voiceBtn {
      width: 100%;
      padding: 12px 20px;
      font-size: 14px;
      font-weight: 600;
      border: none;
      border-radius: 8px;
      background: #FF6B6B;
      color: white;
      cursor: pointer;
      transition: all 0.2s ease;
      margin-bottom: 12px;
    }

    #voiceBtn:hover {
      background: #EE5A5A;
    }

    #voiceBtn.listening {
      background: #51CF66;
      animation: pulse 1.5s infinite;
    }

    @keyframes pulse {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.7; }
    }

    #voiceStatus {
      text-align: center;
      font-size: 12px;
      color: rgba(19, 52, 59, 0.6);
      margin-bottom: 16px;
      min-height: 20px;
    }

    #skipBtn {
      width: 100%;
      padding: 10px 20px;
      font-size: 13px;
      font-weight: 500;
      border: 1px solid rgba(94, 82, 64, 0.2);
      border-radius: 8px;
      background: rgba(94, 82, 64, 0.05);
      color: rgba(19, 52, 59, 1);
      cursor: pointer;
      transition: all 0.2s ease;
    }

    #skipBtn:hover {
      background: rgba(94, 82, 64, 0.1);
    }

    #manualOverlay {
      position: fixed;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      backdrop-filter: blur(8px);
      background: rgba(232, 244, 248, 0.85);
      display: none;
      align-items: center;
      justify-content: center;
      z-index: 1001;
    }

    #manualOverlay.active {
      display: flex;
    }

    .manual-form {
      max-width: 420px;
      width: 90%;
      background: white;
      border-radius: 16px;
      padding: 24px;
      box-shadow: 0 10px 40px rgba(19, 52, 59, 0.15);
      max-height: 80vh;
      overflow-y: auto;
    }

    .manual-form h2 {
      font-size: 18px;
      margin-bottom: 16px;
    }

    .form-group {
      margin-bottom: 16px;
    }

    .form-group label {
      display: block;
      font-size: 12px;
      font-weight: 600;
      margin-bottom: 6px;
    }

    .form-group input,
    .form-group textarea {
      width: 100%;
      padding: 10px 12px;
      font-size: 13px;
      border: 1px solid rgba(94, 82, 64, 0.2);
      border-radius: 6px;
      font-family: inherit;
    }

    .form-group textarea {
      resize: vertical;
      min-height: 80px;
    }

    .button-group {
      display: flex;
      gap: 10px;
      margin-top: 20px;
    }

    .button-group button {
      flex: 1;
      padding: 10px 20px;
      font-size: 13px;
      font-weight: 600;
      border: none;
      border-radius: 8px;
      cursor: pointer;
    }

    .btn-secondary {
      background: rgba(94, 82, 64, 0.1);
      color: rgba(19, 52, 59, 1);
    }

    .btn-primary {
      background: rgba(33, 128, 141, 1);
      color: white;
    }
  </style>
</head>
<body>
  <div id="vrOverlay">
    <div class="overlay-card">
      <h1>ðŸŽ“ Virtual Lecter's Destressing Experience</h1>
      <p>We'll collect information through voice conversation before starting.</p>
      
      <div id="conversationDisplay">
        <div class="message system">
          <strong>System:</strong> Welcome to Virtual Lecter's Destressing Experience
        </div>
      </div>

      <button id="voiceBtn">ðŸŽ¤ Click to Start Voice Conversation</button>
      <div id="voiceStatus">Ready to begin</div>
      <button id="skipBtn">Skip Voice Mode (Use Manual Input)</button>
    </div>
  </div>

  <div id="manualOverlay">
    <div class="manual-form">
      <h2>Basic Information</h2>
      
      <div class="form-group">
        <label>Comfortable Languages</label>
        <input type="text" id="manualLanguages" placeholder="e.g., English, Hindi">
      </div>

      <div class="form-group">
        <label>Preferred Color</label>
        <input type="text" id="manualColor" placeholder="e.g., Blue, Green">
      </div>

      <div class="form-group">
        <label>Emergency Contact (Name and Phone)</label>
        <textarea id="manualEmergency" placeholder="e.g., John Doe, +91-1234567890"></textarea>
      </div>

      <div class="form-group">
        <label>Session Goals</label>
        <textarea id="manualGoals" placeholder="What would you like to work on today?"></textarea>
      </div>

      <div class="button-group">
        <button class="btn-secondary" onclick="closeManualInput()">Back</button>
        <button class="btn-primary" onclick="submitManualData()">Start VR</button>
      </div>
    </div>
  </div>

  <a-scene>
    <a-sky color="#E8F4F8"></a-sky>
    <a-entity light="type: ambient; color: #BBB; intensity: 0.8"></a-entity>
    <a-entity light="type: directional; color: #FFF; intensity: 0.6" position="5 10 7"></a-entity>
    <a-entity light="type: point; color: #FFF; intensity: 0.4" position="0 3.5 0"></a-entity>

    <a-entity 
      gltf-model="https://raw.githubusercontent.com/o-meiuqer-o/classroom_VR4ET/main/assets/models/classroom.glb"
      position="0 0 0"
      rotation="0 180 0"
      scale="1.15 1.15 1.15"
      shadow="cast: true; receive: true">
    </a-entity>

    <a-entity id="rig" position="-0.5 0.6 1.8">
      <a-camera look-controls wasd-controls>
        <a-cursor color="#21808D" raycaster="objects: .clickable"></a-cursor>
      </a-camera>
    </a-entity>

    <!-- Session Start Button -->
    <a-entity id="sessionButton" 
              position="0 1.6 -2"
              visible="false"
              class="clickable">
      <a-plane width="1.5" height="0.5" color="#21808D" opacity="0.95"></a-plane>
      <a-text value="Begin Guided Session" 
              position="0 0 0.01" 
              align="center"
              width="2.5"
              color="#FFFFFF"
              font="roboto"
              wrap-count="30"></a-text>
    </a-entity>

    <!-- Feedback Buttons (hidden initially) -->
    <a-entity id="feedbackButtons" visible="false">
      <a-entity id="thumbsUpBtn" position="-0.5 1.5 -1.8" class="clickable">
        <a-plane width="0.6" height="0.4" color="#51CF66"></a-plane>
        <a-text value="ðŸ‘ Yes" position="0 0 0.01" align="center" width="1.2" color="#FFF"></a-text>
      </a-entity>
      
      <a-entity id="thumbsDownBtn" position="0.5 1.5 -1.8" class="clickable">
        <a-plane width="0.6" height="0.4" color="#FF6B6B"></a-plane>
        <a-text value="ðŸ‘Ž Not Really" position="0 0 0.01" align="center" width="1.2" color="#FFF"></a-text>
      </a-entity>
    </a-entity>

    <!-- Text Display (for showing numbers 5-4-3-2-1) -->
    <a-text id="displayText" 
            position="0 2 -1.8" 
            align="center" 
            width="3"
            color="#21808D"
            visible="false"></a-text>
  </a-scene>

  <script>
    console.log('VR Classroom v29 - Grounding Exercise - Initialized');

    const sessionData = {
      comfortableLanguages: '',
      preferredColor: '',
      emergencyContact: '',
      goals: '',
      startTime: new Date()
    };

    let recognition = null;
    let synthesis = window.speechSynthesis;
    let voices = [];
    let recognitionTimeout = null;
    let isSpeaking = false;

    // Grounding exercise state
    let groundingStep = 0;
    const groundingSteps = [
      { text: "We're starting with a grounding exercise. This isn't about relaxation yetâ€”this is about bringing you fully into the present moment so your brain knows where you are and what's real.", duration: 6000 },
      { text: "It's called 5-4-3-2-1. We're going to use your senses. I'll guide you.", duration: 4000, showNumbers: true },
      { text: "Look around. FIVE things you can SEE right now. Name them out loud or in your head.", duration: 8000 },
      { text: "FOUR things you can TOUCH or feel right now. Actually reach out and touch them if you can. The chair under you? Your shirt? The floor under your feet? Your hair?", duration: 8000 },
      { text: "THREE things you can HEAR right now. Could be my voice, background sounds, maybe your own breathing.", duration: 8000 },
      { text: "TWO things you can SMELL. If you can't smell anything obvious, that's fineâ€”just notice that.", duration: 5000 },
      { text: "ONE thing you can TASTE. Maybe you brushed your teeth earlier, or had water. Or maybe you don't taste anythingâ€”that's fine too.", duration: 5000 },
      { text: "Good. Now take one deep breath in... and out.", duration: 4000 },
      { text: "Small check-in - do you feel a little more here? A little more solid?", duration: 3000, showFeedback: true },
      { text: "Good. That grounding technique! You can use that in the exam hall if you start feeling spaced out. We'll come back to that.", duration: 5000, positive: true },
      { text: "That's okay. Sometimes it takes a few tries. We can do it again later if needed.", duration: 4000, negative: true }
    ];

    if (synthesis) {
      synthesis.onvoiceschanged = () => {
        voices = synthesis.getVoices();
        console.log('Voices loaded:', voices.length);
      };
    }

    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognition = new SpeechRecognition();
      recognition.continuous = false;
      recognition.interimResults = true;
      recognition.lang = 'en-US';
      console.log('Speech Recognition initialized');
    }

    let conversationState = {
      step: 'welcome',
      responses: {},
      isListening: false
    };

    const conversationFlow = {
      welcome: {
        text: "Welcome to Virtual Lecter's Destressing Experience. We'll practice safely in a virtual classroom. Before we begin, I will ask a few questions. Are you ready to start?",
        nextStep: 'language'
      },
      language: {
        text: "Which languages are you comfortable with? Feel free to mention one or more.",
        nextStep: 'color',
        saveAs: 'comfortableLanguages'
      },
      color: {
        text: "What is your preferred color for the virtual environment?",
        nextStep: 'emergencyContact',
        saveAs: 'preferredColor'
      },
      emergencyContact: {
        text: "For your safety, please provide the name and phone number of an emergency contact person.",
        nextStep: 'goals',
        saveAs: 'emergencyContact'
      },
      goals: {
        text: "What would you like to work on today?",
        nextStep: 'complete',
        saveAs: 'goals'
      },
      complete: {
        text: "Thank you. We're ready to begin. Are you ready to enter the virtual environment?",
        nextStep: 'vr'
      }
    };

    function speak(text, callback) {
      console.log('Speaking:', text.substring(0, 40) + '...');
      
      if (!synthesis) {
        console.log('Speech synthesis not available');
        if (callback) setTimeout(callback, 500);
        return;
      }

      synthesis.cancel();
      isSpeaking = true;

      const utterance = new SpeechSynthesisUtterance(text);
      utterance.rate = 0.85;
      utterance.lang = 'en-US';

      if (voices.length > 0) {
        const voice = voices.find(v => v.lang.includes('en') && v.name.includes('Female')) || voices[0];
        utterance.voice = voice;
      }

      let completed = false;
      const finishSpeech = () => {
        if (!completed) {
          completed = true;
          isSpeaking = false;
          console.log('Speech completed');
          if (callback) {
            setTimeout(callback, 1000);
          }
        }
      };

      utterance.onend = finishSpeech;
      utterance.onerror = (e) => {
        console.error('Speech error:', e);
        finishSpeech();
      };

      const wordCount = text.split(' ').length;
      const estimatedDuration = (wordCount * 150) + 2000;
      setTimeout(finishSpeech, estimatedDuration);

      addMessage('System', text);
      synthesis.speak(utterance);
    }

    function addMessage(sender, text) {
      const display = document.getElementById('conversationDisplay');
      const msg = document.createElement('div');
      msg.className = `message ${sender.toLowerCase()}`;
      msg.innerHTML = `<strong>${sender}:</strong> ${text}`;
      display.appendChild(msg);
      display.scrollTop = display.scrollHeight;
    }

    async function requestMicPermission() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        stream.getTracks().forEach(track => track.stop());
        console.log('Microphone permission granted');
        return true;
      } catch (error) {
        console.error('Microphone permission denied:', error);
        alert('Please allow microphone access.');
        return false;
      }
    }

    async function startConversation() {
      const voiceBtn = document.getElementById('voiceBtn');
      const statusEl = document.getElementById('voiceStatus');

      const currentStep = conversationState.step;
      const currentFlow = conversationFlow[currentStep];

      if (currentStep !== 'welcome' && Object.keys(conversationState.responses).length > 0) {
        console.log('Resuming conversation');
        voiceBtn.textContent = 'ðŸ”Š Resuming...';
        speak("Let's continue. " + currentFlow.text, () => {
          startListening(currentStep);
        });
        return;
      }

      voiceBtn.textContent = 'ðŸŽ¤ Requesting microphone...';
      const hasPermission = await requestMicPermission();
      
      if (!hasPermission) {
        voiceBtn.textContent = 'ðŸŽ¤ Click to Start';
        statusEl.textContent = 'âŒ Microphone denied';
        return;
      }

      voiceBtn.textContent = 'ðŸ”Š Speaking...';
      speak(conversationFlow.welcome.text, () => {
        startListening('welcome');
      });
    }

    function startListening(step) {
      if (!recognition) {
        alert('Voice recognition not supported. Use manual input.');
        return;
      }

      console.log('Starting to listen for:', step);
      
      const voiceBtn = document.getElementById('voiceBtn');
      const statusEl = document.getElementById('voiceStatus');

      conversationState.step = step;
      conversationState.isListening = true;

      voiceBtn.textContent = 'ðŸŽ¤ Listening...';
      voiceBtn.classList.add('listening');
      statusEl.textContent = 'ðŸ”´ LISTENING';
      statusEl.style.color = '#FF6B6B';
      statusEl.style.fontWeight = 'bold';

      if (recognitionTimeout) clearTimeout(recognitionTimeout);

      recognitionTimeout = setTimeout(() => {
        console.log('Recognition timeout');
        recognition.stop();
      }, 60000);

      recognition.onresult = (event) => {
        let finalTranscript = '';
        
        for (let i = event.resultIndex; i < event.results.length; i++) {
          if (event.results[i].isFinal) {
            finalTranscript += event.results[i][0].transcript;
          } else {
            statusEl.textContent = `ðŸ“ "${event.results[i][0].transcript}"`;
          }
        }

        if (finalTranscript) {
          const transcript = finalTranscript.trim();
          console.log('Final result:', transcript);

          if (recognitionTimeout) clearTimeout(recognitionTimeout);
          conversationState.isListening = false;

          voiceBtn.classList.remove('listening');
          voiceBtn.textContent = 'âœ… Got it!';
          statusEl.textContent = `You said: "${transcript}"`;
          statusEl.style.color = '#51CF66';

          addMessage('You', transcript);
          processResponse(transcript, step);
        }
      };

      recognition.onerror = (event) => {
        console.error('Recognition error:', event.error);
        voiceBtn.classList.remove('listening');
        voiceBtn.textContent = 'ðŸ”„ Click to Resume';
        statusEl.textContent = 'Error: ' + event.error;
        conversationState.isListening = false;
      };

      recognition.onend = () => {
        console.log('Recognition ended');
        if (conversationState.isListening) {
          setTimeout(() => {
            try {
              recognition.start();
            } catch (e) {
              console.error('Restart failed:', e);
            }
          }, 100);
        }
      };

      try {
        recognition.start();
      } catch (error) {
        console.error('Failed to start:', error);
      }
    }

    function processResponse(transcript, step) {
      const currentFlow = conversationFlow[step];
      
      if (currentFlow.saveAs) {
        conversationState.responses[currentFlow.saveAs] = transcript;
      }

      if (currentFlow.nextStep === 'vr') {
        completeConversation();
      } else {
        setTimeout(() => continueConversation(currentFlow.nextStep), 1000);
      }
    }

    function continueConversation(nextStep) {
      const nextFlow = conversationFlow[nextStep];
      const voiceBtn = document.getElementById('voiceBtn');
      const statusEl = document.getElementById('voiceStatus');

      voiceBtn.textContent = 'ðŸ”Š Speaking...';
      voiceBtn.classList.remove('listening');
      statusEl.textContent = 'Speaking';
      statusEl.style.color = '';
      statusEl.style.fontWeight = '';

      speak(nextFlow.text, () => {
        startListening(nextStep);
      });
    }

    function completeConversation() {
      Object.assign(sessionData, conversationState.responses);
      console.log('Conversation complete:', sessionData);

      const voiceBtn = document.getElementById('voiceBtn');
      voiceBtn.textContent = 'âœ… Complete';

      setTimeout(() => {
        document.getElementById('vrOverlay').classList.add('hidden');
        document.getElementById('sessionButton').setAttribute('visible', 'true');
        speak('Welcome to the virtual classroom. When ready, click the Begin Guided Session button.');
      }, 2000);
    }

    function showManualInput() {
      document.getElementById('manualOverlay').classList.add('active');
    }

    function closeManualInput() {
      document.getElementById('manualOverlay').classList.remove('active');
    }

    function submitManualData() {
      sessionData.comfortableLanguages = document.getElementById('manualLanguages').value;
      sessionData.preferredColor = document.getElementById('manualColor').value;
      sessionData.emergencyContact = document.getElementById('manualEmergency').value;
      sessionData.goals = document.getElementById('manualGoals').value;

      console.log('Manual data submitted:', sessionData);
      closeManualInput();
      document.getElementById('vrOverlay').classList.add('hidden');
      document.getElementById('sessionButton').setAttribute('visible', 'true');
      speak('Welcome to the virtual classroom. When ready, click the Begin Guided Session button.');
    }

    // Grounding Exercise Functions
    function startGuidedSession() {
      console.log('Starting guided session - Phase 1: Grounding');
      groundingStep = 0;
      document.getElementById('sessionButton').setAttribute('visible', 'false');
      nextGroundingStep();
    }

    function nextGroundingStep() {
      if (groundingStep >= groundingSteps.length - 2) return;

      const step = groundingSteps[groundingStep];
      console.log('Grounding step', groundingStep, ':', step.text.substring(0, 40));

      // Show numbers for step 1
      if (step.showNumbers) {
        document.getElementById('displayText').setAttribute('value', '5  4  3  2  1');
        document.getElementById('displayText').setAttribute('visible', 'true');
        setTimeout(() => {
          document.getElementById('displayText').setAttribute('visible', 'false');
        }, 3000);
      }

      // Show feedback buttons for step 8
      if (step.showFeedback) {
        speak(step.text, () => {
          document.getElementById('feedbackButtons').setAttribute('visible', 'true');
        });
        return;
      }

      speak(step.text, () => {
        setTimeout(() => {
          groundingStep++;
          nextGroundingStep();
        }, step.duration);
      });
    }

    function handleFeedback(isPositive) {
      document.getElementById('feedbackButtons').setAttribute('visible', 'false');
      const responseStep = isPositive ? 9 : 10;
      speak(groundingSteps[responseStep].text, () => {
        console.log('Grounding exercise complete');
        speak('Phase 1 complete. The full session will continue in future updates.');
      });
    }

    // Event Listeners
    document.getElementById('voiceBtn').addEventListener('click', startConversation);
    document.getElementById('skipBtn').addEventListener('click', showManualInput);

    document.addEventListener('DOMContentLoaded', () => {
      const sessionBtn = document.getElementById('sessionButton');
      sessionBtn.addEventListener('click', startGuidedSession);

      document.getElementById('thumbsUpBtn').addEventListener('click', () => handleFeedback(true));
      document.getElementById('thumbsDownBtn').addEventListener('click', () => handleFeedback(false));
    });
  </script>
</body>
</html>

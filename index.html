<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>VR Classroom Exposure Therapy</title>
  <script src="https://aframe.io/releases/1.4.2/aframe.min.js"></script>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
      overflow: hidden;
      background: linear-gradient(135deg, #E8F4F8 0%, #F0F8FA 100%);
    }

    /* VR Overlay */
    #vrOverlay {
      position: fixed;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      backdrop-filter: blur(8px);
      background: rgba(232, 244, 248, 0.85);
      display: flex;
      align-items: center;
      justify-content: center;
      z-index: 1000;
      transition: opacity 0.5s ease, visibility 0.5s ease;
    }

    #vrOverlay.hidden {
      opacity: 0;
      visibility: hidden;
      pointer-events: none;
    }

    .overlay-card {
      max-width: 420px;
      width: 90%;
      background: white;
      border-radius: 16px;
      padding: 24px;
      box-shadow: 0 10px 40px rgba(19, 52, 59, 0.15);
      animation: slideUp 0.4s ease;
    }

    @keyframes slideUp {
      from {
        opacity: 0;
        transform: translateY(20px);
      }
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    .overlay-card h1 {
      font-size: 20px;
      color: rgba(19, 52, 59, 1);
      margin-bottom: 8px;
      font-weight: 600;
    }

    .overlay-card p {
      font-size: 13px;
      color: rgba(19, 52, 59, 0.7);
      margin-bottom: 20px;
      line-height: 1.5;
    }

    /* Conversation Display */
    #conversationDisplay {
      max-height: 200px;
      overflow-y: auto;
      margin-bottom: 16px;
      padding: 12px;
      background: rgba(232, 244, 248, 0.5);
      border-radius: 8px;
    }

    .message {
      margin-bottom: 10px;
      padding: 8px 12px;
      border-radius: 8px;
      font-size: 12px;
      line-height: 1.4;
    }

    .message.system {
      background: rgba(33, 128, 141, 0.1);
      color: rgba(19, 52, 59, 1);
      border-left: 3px solid rgba(33, 128, 141, 1);
    }

    .message.user {
      background: rgba(33, 128, 141, 0.2);
      color: rgba(19, 52, 59, 1);
      text-align: right;
      border-right: 3px solid rgba(33, 128, 141, 1);
    }

    /* Live Caption */
    #liveCaption {
      min-height: 40px;
      padding: 10px;
      background: rgba(255, 255, 255, 0.8);
      border-radius: 8px;
      margin-bottom: 16px;
      font-size: 12px;
      color: rgba(19, 52, 59, 0.6);
      font-style: italic;
      text-align: center;
    }

    /* Voice Button */
    #voiceButton {
      width: 100%;
      padding: 14px;
      border: none;
      border-radius: 8px;
      background: #FF6B6B;
      color: white;
      font-size: 14px;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.3s ease;
      margin-bottom: 12px;
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 8px;
    }

    #voiceButton:hover {
      transform: translateY(-2px);
      box-shadow: 0 4px 12px rgba(255, 107, 107, 0.3);
    }

    #voiceButton.listening {
      background: #51CF66;
      animation: pulse 1.5s infinite;
    }

    @keyframes pulse {
      0%, 100% {
        opacity: 1;
      }
      50% {
        opacity: 0.7;
      }
    }

    #voiceButton.processing {
      background: #FFA94D;
      cursor: not-allowed;
    }

    #voiceButton:disabled {
      opacity: 0.6;
      cursor: not-allowed;
    }

    .status-icon {
      width: 10px;
      height: 10px;
      border-radius: 50%;
      background: white;
      display: inline-block;
      animation: blink 1s infinite;
    }

    @keyframes blink {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.3; }
    }

    #skipButton {
      width: 100%;
      padding: 10px;
      border: 2px solid rgba(33, 128, 141, 1);
      border-radius: 8px;
      background: transparent;
      color: rgba(33, 128, 141, 1);
      font-size: 13px;
      font-weight: 500;
      cursor: pointer;
      transition: all 0.3s ease;
    }

    #skipButton:hover {
      background: rgba(33, 128, 141, 0.1);
    }

    /* Manual Input Overlay */
    #manualInputOverlay {
      display: none;
    }

    #manualInputOverlay.active {
      display: flex;
    }

    .form-group {
      margin-bottom: 16px;
    }

    .form-group label {
      display: block;
      font-size: 13px;
      font-weight: 500;
      color: rgba(19, 52, 59, 1);
      margin-bottom: 6px;
    }

    .form-group input,
    .form-group textarea {
      width: 100%;
      padding: 10px 12px;
      border: 1px solid rgba(19, 52, 59, 0.2);
      border-radius: 6px;
      font-size: 13px;
      font-family: inherit;
      transition: border-color 0.3s ease;
    }

    .form-group input:focus,
    .form-group textarea:focus {
      outline: none;
      border-color: rgba(33, 128, 141, 1);
    }

    .form-group textarea {
      resize: vertical;
      min-height: 60px;
    }

    .button-group {
      display: flex;
      gap: 10px;
      margin-top: 20px;
    }

    .button-group button {
      flex: 1;
      padding: 12px;
      border: none;
      border-radius: 8px;
      font-size: 13px;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.3s ease;
    }

    .button-group button.primary {
      background: rgba(33, 128, 141, 1);
      color: white;
    }

    .button-group button.primary:hover {
      background: rgba(33, 128, 141, 0.9);
    }

    .button-group button.secondary {
      background: rgba(19, 52, 59, 0.1);
      color: rgba(19, 52, 59, 1);
    }

    .button-group button.secondary:hover {
      background: rgba(19, 52, 59, 0.15);
    }

    /* Permission Instructions */
    #permissionInstructions {
      display: none;
      margin-top: 12px;
      padding: 12px;
      background: rgba(255, 193, 7, 0.1);
      border-left: 3px solid #FFC107;
      border-radius: 4px;
      font-size: 11px;
      color: rgba(19, 52, 59, 0.8);
      line-height: 1.5;
    }

    #permissionInstructions.show {
      display: block;
    }

    /* Status Message */
    #statusMessage {
      text-align: center;
      padding: 8px;
      font-size: 11px;
      color: rgba(19, 52, 59, 0.6);
      font-weight: 500;
    }
  </style>
</head>
<body>
  <!-- VR Scene -->
  <a-scene>
    <!-- Sky -->
    <a-sky color="#E8F4F8"></a-sky>

    <!-- Lighting -->
    <a-entity light="type: ambient; color: #BBB; intensity: 0.8"></a-entity>
    <a-entity light="type: directional; intensity: 0.6" position="5 10 7"></a-entity>
    <a-entity light="type: point; intensity: 0.4" position="0 3.5 0"></a-entity>

    <!-- Camera Rig -->
    <a-entity id="cameraRig" position="-0.5 0.6 1.8">
      <a-camera wasd-controls="acceleration: 20" look-controls="pointerLockEnabled: true">
        <a-cursor></a-cursor>
      </a-camera>
    </a-entity>

    <!-- Classroom Model -->
    <a-entity 
      id="classroom"
      gltf-model="https://raw.githubusercontent.com/o-meiuqer-o/classroom_VR4ET/main/assets/models/classroom.glb"
      position="0 0 0"
      rotation="0 180 0"
      scale="1.15 1.15 1.15">
    </a-entity>
  </a-scene>

  <!-- Voice Mode Overlay -->
  <div id="vrOverlay">
    <div class="overlay-card">
      <h1>Virtual Lecter's Experience</h1>
      <p>Welcome to your safe virtual classroom for destressing practice.</p>

      <div id="conversationDisplay"></div>
      <div id="liveCaption">Your responses will appear here...</div>

      <button id="voiceButton">
        <span class="status-icon"></span>
        <span id="voiceButtonText">Start Voice Conversation</span>
      </button>

      <button id="skipButton">Use Manual Input Instead</button>

      <div id="permissionInstructions">
        <strong>Microphone Access Required:</strong><br>
        â€¢ Chrome/Edge: Click the camera icon in the address bar<br>
        â€¢ Firefox: Click the microphone icon in the address bar<br>
        â€¢ Safari: Go to Settings â†’ Websites â†’ Microphone<br>
        Please allow microphone access and try again.
      </div>

      <div id="statusMessage"></div>
    </div>
  </div>

  <!-- Manual Input Overlay -->
  <div id="manualInputOverlay" class="vrOverlay">
    <div class="overlay-card">
      <h1>Session Information</h1>
      <p>Please provide some information to personalize your experience.</p>

      <form id="manualForm">
        <div class="form-group">
          <label>Comfortable Languages</label>
          <input type="text" id="manualLanguages" placeholder="e.g., English, Spanish" required>
        </div>

        <div class="form-group">
          <label>Preferred Color for Environment</label>
          <input type="text" id="manualColor" placeholder="e.g., blue, green, warm" required>
        </div>

        <div class="form-group">
          <label>Emergency Contact (Name &amp; Phone)</label>
          <input type="text" id="manualContact" placeholder="e.g., John Smith 555-1234" required>
        </div>

        <div class="form-group">
          <label>Session Goals</label>
          <textarea id="manualGoals" placeholder="What would you like to work on today?" required></textarea>
        </div>

        <div class="button-group">
          <button type="button" class="secondary" id="backButton">Back</button>
          <button type="submit" class="primary">Begin VR Session</button>
        </div>
      </form>
    </div>
  </div>

  <script>
    // Session Data Storage
    const sessionData = {
      comfortableLanguages: '',
      preferredColor: '',
      emergencyContact: '',
      goals: '',
      exposureLevel: 'gentle',
      startTime: null,
      conversationHistory: []
    };

    // Conversation Flow
    const conversationFlow = {
      welcome: {
        text: "Welcome to Virtual Lecter's Destressing Experience. We'll practice safely in a virtual classroom. Before we begin, I will ask a few questions to personalize your experience. Are you ready to start?",
        nextStep: 'language',
        saveAs: null
      },
      language: {
        text: "Which languages are you comfortable with? Feel free to mention one or more.",
        nextStep: 'color',
        saveAs: 'comfortableLanguages'
      },
      color: {
        text: "What is your preferred color for the virtual environment?",
        nextStep: 'emergencyContact',
        saveAs: 'preferredColor'
      },
      emergencyContact: {
        text: "For your safety, please provide the name and phone number of an emergency contact person.",
        nextStep: 'goals',
        saveAs: 'emergencyContact'
      },
      goals: {
        text: "What would you like to work on today? For example, 'reduce anxiety when presenting' or 'feel comfortable in class'.",
        nextStep: 'complete',
        saveAs: 'goals'
      },
      complete: {
        text: "Thank you for sharing. We're now ready to begin your virtual classroom experience. Are you ready to enter the virtual environment?",
        nextStep: 'vr',
        saveAs: null
      }
    };

    // DOM Elements
    const vrOverlay = document.getElementById('vrOverlay');
    const manualInputOverlay = document.getElementById('manualInputOverlay');
    const conversationDisplay = document.getElementById('conversationDisplay');
    const liveCaption = document.getElementById('liveCaption');
    const voiceButton = document.getElementById('voiceButton');
    const voiceButtonText = document.getElementById('voiceButtonText');
    const skipButton = document.getElementById('skipButton');
    const permissionInstructions = document.getElementById('permissionInstructions');
    const statusMessage = document.getElementById('statusMessage');
    const manualForm = document.getElementById('manualForm');
    const backButton = document.getElementById('backButton');

    // Voice Recognition
    let recognition = null;
    let currentStep = 'welcome';
    let isListening = false;
    let timeoutId = null;
    let speechSynthesis = window.speechSynthesis;

    // Initialize Speech Recognition
    function initSpeechRecognition() {
      if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
        alert('Speech recognition is not supported in your browser. Please use Chrome, Edge, or Safari.');
        return false;
      }

      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognition = new SpeechRecognition();
      recognition.continuous = false;
      recognition.interimResults = true;
      recognition.lang = 'en-US';

      recognition.onstart = () => {
        isListening = true;
        updateButtonState('listening');
        liveCaption.textContent = 'Listening...';
        
        // Set 30-second timeout
        timeoutId = setTimeout(() => {
          if (isListening) {
            recognition.stop();
            updateStatus('No speech detected. Click the button to try again.');
          }
        }, 30000);
      };

      recognition.onresult = (event) => {
        let interimTranscript = '';
        let finalTranscript = '';

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript;
          } else {
            interimTranscript += transcript;
          }
        }

        liveCaption.textContent = interimTranscript || finalTranscript || 'Listening...';

        if (finalTranscript) {
          clearTimeout(timeoutId);
          handleUserResponse(finalTranscript.trim());
        }
      };

      recognition.onerror = (event) => {
        clearTimeout(timeoutId);
        isListening = false;
        
        if (event.error === 'not-allowed' || event.error === 'permission-denied') {
          permissionInstructions.classList.add('show');
          updateStatus('Microphone permission denied. Please allow access.');
        } else if (event.error === 'no-speech') {
          updateStatus('No speech detected. Click to try again.');
        } else {
          updateStatus(`Error: ${event.error}. Click to try again.`);
        }
        
        updateButtonState('ready');
      };

      recognition.onend = () => {
        clearTimeout(timeoutId);
        isListening = false;
        if (voiceButton.classList.contains('listening')) {
          updateButtonState('ready');
        }
      };

      return true;
    }

    // Speak Text with Bulletproof Callback System
    function speak(text, callback) {
      console.log('ðŸ”Š Speaking:', text.substring(0, 50) + '...');
      
      speechSynthesis.cancel();
      
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.rate = 0.9;
      utterance.pitch = 1;
      utterance.volume = 1;
      
      // Calculate estimated duration (roughly 150ms per word + 1 second buffer)
      const wordCount = text.split(' ').length;
      const estimatedDuration = (wordCount * 150) + 1000;
      console.log('â±ï¸ Estimated speech duration:', estimatedDuration + 'ms');
      
      let callbackExecuted = false;
      const executeCallback = () => {
        if (!callbackExecuted && callback) {
          callbackExecuted = true;
          console.log('ðŸŽ¤ Callback executed - starting listening');
          callback();
        }
      };
      
      // Primary callback: utterance.onend
      utterance.onend = () => {
        console.log('âœ… Speech ended (onend)');
        executeCallback();
      };
      
      // Error fallback
      utterance.onerror = (event) => {
        console.log('âš ï¸ Speech error:', event.error);
        executeCallback();
      };
      
      // Fallback 1: Timeout based on estimated duration
      const fallbackTimeout = setTimeout(() => {
        console.log('â° Fallback timeout triggered');
        executeCallback();
      }, estimatedDuration);
      
      // Fallback 2: Safety net if onend doesn't fire within 1 second after estimated time
      const safetyTimeout = setTimeout(() => {
        console.log('ðŸš¨ Safety timeout triggered');
        executeCallback();
      }, estimatedDuration + 1000);
      
      utterance.onstart = () => {
        console.log('ðŸŽ¬ Speech started');
      };
      
      try {
        speechSynthesis.speak(utterance);
        
        // Additional safety: If speechSynthesis fails to speak, trigger callback immediately
        setTimeout(() => {
          if (speechSynthesis.speaking === false && !callbackExecuted) {
            console.log('âŒ Speech failed to start - triggering callback immediately');
            executeCallback();
          }
        }, 100);
      } catch (error) {
        console.error('âŒ Speech synthesis error:', error);
        executeCallback();
      }
    }

    // Add Message to Conversation
    function addMessage(text, type) {
      const messageDiv = document.createElement('div');
      messageDiv.className = `message ${type}`;
      messageDiv.textContent = text;
      conversationDisplay.appendChild(messageDiv);
      conversationDisplay.scrollTop = conversationDisplay.scrollHeight;
      
      sessionData.conversationHistory.push({ type, text, timestamp: new Date().toISOString() });
    }

    // Update Button State
    function updateButtonState(state) {
      voiceButton.className = '';
      
      switch (state) {
        case 'ready':
          voiceButton.classList.remove('listening', 'processing');
          voiceButtonText.textContent = currentStep === 'welcome' ? 'Start Voice Conversation' : 'Continue';
          voiceButton.disabled = false;
          break;
        case 'listening':
          voiceButton.classList.add('listening');
          voiceButtonText.textContent = 'LISTENING...';
          voiceButton.disabled = false;
          break;
        case 'processing':
          voiceButton.classList.add('processing');
          voiceButtonText.textContent = 'PROCESSING...';
          voiceButton.disabled = true;
          break;
        case 'speaking':
          voiceButton.classList.add('processing');
          voiceButtonText.textContent = 'SPEAKING...';
          voiceButton.disabled = true;
          break;
      }
    }

    // Update Status Message
    function updateStatus(message) {
      statusMessage.textContent = message;
      setTimeout(() => {
        statusMessage.textContent = '';
      }, 5000);
    }

    // Handle User Response
    function handleUserResponse(response) {
      updateButtonState('processing');
      liveCaption.textContent = `Got it: "${response}"`;
      addMessage(response, 'user');

      const step = conversationFlow[currentStep];
      
      // Save response if needed
      if (step.saveAs) {
        sessionData[step.saveAs] = response;
      }

      // Move to next step
      setTimeout(() => {
        proceedToNextStep();
      }, 1000);
    }

    // Proceed to Next Step
    function proceedToNextStep() {
      const step = conversationFlow[currentStep];
      const nextStep = step.nextStep;

      if (nextStep === 'vr') {
        // Complete conversation
        updateButtonState('speaking');
        speak('Great! Entering the virtual classroom now.', () => {
          completeSession();
        });
      } else {
        currentStep = nextStep;
        const nextStepData = conversationFlow[nextStep];
        
        updateButtonState('speaking');
        addMessage(nextStepData.text, 'system');
        
        // Speak and auto-start listening after
        speak(nextStepData.text, () => {
          liveCaption.textContent = 'Ready to listen...';
          setTimeout(() => {
            startListening();
          }, 500);
        });
      }
    }

    // Start Listening
    function startListening() {
      console.log('ðŸ‘‚ Starting voice recognition');
      try {
        recognition.start();
        console.log('âœ… Recognition started');
      } catch (error) {
        console.error('âŒ Recognition start error:', error);
        updateStatus('Error starting recognition. Please try again.');
        updateButtonState('ready');
      }
    }

    // Start Voice Conversation
    function startVoiceConversation() {
      console.log('ðŸŽ¬ Starting conversation');
      
      if (!recognition && !initSpeechRecognition()) {
        return;
      }

      if (isListening) {
        recognition.stop();
        return;
      }

      // If first time, speak welcome message and auto-start listening
      if (currentStep === 'welcome') {
        sessionData.startTime = new Date().toISOString();
        updateButtonState('speaking');
        const welcomeText = conversationFlow.welcome.text;
        addMessage(welcomeText, 'system');
        
        // Speak with callback to auto-start listening
        speak(welcomeText, () => {
          liveCaption.textContent = 'Ready to listen...';
          setTimeout(() => {
            startListening();
          }, 500);
        });
      } else {
        // Start listening immediately
        startListening();
      }
    }

    // Complete Session
    function completeSession() {
      console.log('Session Data:', sessionData);
      vrOverlay.classList.add('hidden');
      updateStatus('Welcome to your virtual classroom!');
    }

    // Switch to Manual Input
    function switchToManualInput() {
      vrOverlay.style.display = 'none';
      manualInputOverlay.classList.add('active');
    }

    // Back to Voice Mode
    function backToVoiceMode() {
      manualInputOverlay.classList.remove('active');
      vrOverlay.style.display = 'flex';
    }

    // Handle Manual Form Submit
    function handleManualSubmit(e) {
      e.preventDefault();
      
      sessionData.comfortableLanguages = document.getElementById('manualLanguages').value;
      sessionData.preferredColor = document.getElementById('manualColor').value;
      sessionData.emergencyContact = document.getElementById('manualContact').value;
      sessionData.goals = document.getElementById('manualGoals').value;
      sessionData.startTime = new Date().toISOString();

      console.log('Session Data (Manual):', sessionData);
      
      manualInputOverlay.classList.remove('active');
      vrOverlay.classList.add('hidden');
      
      speak('Welcome to your virtual classroom. Take your time to explore.', null);
    }

    // Event Listeners
    voiceButton.addEventListener('click', startVoiceConversation);
    skipButton.addEventListener('click', switchToManualInput);
    backButton.addEventListener('click', backToVoiceMode);
    manualForm.addEventListener('submit', handleManualSubmit);

    // Initialize
    document.addEventListener('DOMContentLoaded', () => {
      console.log('VR Classroom Exposure Therapy Initialized');
    });
  </script>
</body>
</html>
